---
layout: page
---

<div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="flex: 1; padding-right: 20px;">
            <img src="images/lily.jpg" alt="Your Image" style="max-width: 80%;  display: block;">
            <br> 
<!--                 <a href="/files/cv.pdf">CV</a>  / -->
            <p style="margin-left: 3%">  <a href="mailto:lily.goli@mail.utoronto.ca">Email</a>  /  <a href="https://scholar.google.com/citations?user=2wnyE-8AAAAJ&hl=en">Scholar</a>  /  <a href="https://github.com/lilygoli">Github</a>  /  <a href="https://twitter.com/lily_goli">Twitter</a></p> 
        </div>
        <div style="flex: 1; padding-left: 0px; padding-right: 10px">
            <p style="text-align: justify;">I am a PhD student in Computer Science at University of Toronto, co-advised by <a href="https://www.cs.toronto.edu/~jacobson" target="_blank" rel="noopener noreferrer"> Alec Jacobson </a> and <a href="https://taiya.github.io" target="_blank" rel="noopener noreferrer">Andrea Tagliasacchi</a>. I am currently focused on improving robustness in 3D models like Radiance Fields and enabling them to work seamlessly with 3D processing tools. More broadly, I am interested in 3D Computer Vision and Graphics. I am currently a research intern at <a href="https://waabi.ai/" target="_blank" rel="noopener noreferrer">Waabi</a> and previously worked at Google DeepMind as a student researcher.</p>
            <p style="text-align: justify;">Previously, I did my B.Sc. in Sharif University of Technology, during which I had two wonderful internships at <a href="https://www.cs.cit.tum.de/en/camp/labs-locations/ifl-lab/" target="_blank" rel="noopener noreferrer">IFL lab</a> working with <a href="https://www.professoren.tum.de/en/navab-nassir" target="_blank" rel="noopener noreferrer">Nassir Navab</a>, and at <a href="https://rcl.ece.ubc.ca/" target="_blank" rel="noopener noreferrer">RCL lab</a> with <a href="https://ece.ubc.ca/purang-abolmaesumi/" target="_blank" rel="noopener noreferrer">Purang Abolmaesumi</a>.</p>
              <p style="text-align: justify;"> I held a <a href="https://3dvisionreadinggroup.github.io/" target="_blank" rel="noopener noreferrer">3D Vision reading group</a> at UofT in 2023.  Feel free to <a href="mailto:lily.goli@mail.utoronto.ca" >get in touch</a> if you're interested and would like to help organizing another round of the reading group.</p>  
        </div>
</div>
<hr style="margin-top: 20px; margin-bottom: 20px;">
<div>
        <h2 style="color: #424242;font-size: 27px; font-family: Helvetica-light, serif;">Publications</h2>

         <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 20px;">
            <div style="flex: 1; padding: 20px;">
                <img src="/images/romo.gif" alt="Publication Image 1" style="max-width: 70%;  display: block;">
                <p style="margin-left: 14%"> <a href="https://romosfm.github.io" target="_blank" rel="noopener noreferrer">Page</a> / <a href="https://arxiv.org/abs/2411.18650" target="_blank" rel="noopener noreferrer">Arxiv</a></p>
            </div>
            <div style="flex: 1; padding: 20px;">
                <p> <b>RoMo: Robust Motion Segmentation Improves Structure from Motion</b> </p>
                <p> <b>Lily Goli*</b>, Sara Sabour*, Mark Matthews, Marcus Brubaker, Dmitry Lagun, Alec Jacobson, David J. Fleet, Saurabh Saxena*, Andrea Tagliasacchi* </p>
                <p><i>ICCV 2025</i></p>
            </div>
        </div>       

        <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 20px;">
            <div style="flex: 1; padding: 20px;">
                <img src="/images/sls.gif" alt="Publication Image 1" style="max-width: 70%;  display: block;">
                <p style="margin-left: 14%"> <a href="https://spotlesssplats.github.io" target="_blank" rel="noopener noreferrer">Page</a> / <a href="https://arxiv.org/abs/2406.20055" target="_blank" rel="noopener noreferrer">Arxiv</a> / <a href="https://github.com/lilygoli/SpotLessSplats/tree/main" target="_blank" rel="noopener noreferrer">Code</a></p>
            </div>
            <div style="flex: 1; padding: 20px;">
                <p> <b>SpotlessSplats: Ignoring Distractors in 3D Gaussian Splatting</b> </p>
                <p> <b>Lily Goli*</b>, Sara Sabour*, George Kopanas, Mark Matthews, Dmitry Lagun, Leonidas Guibas, Alec Jacobson, David J. Fleet, Andrea Tagliasacchi </p>
                <p><i>Transactions on Graphics (TOG) 2025</i></p>
            </div>
        </div>
        
        <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 20px;">
            <div style="flex: 1; padding: 20px;">
                <img src="/images/bayesrays.gif" alt="Publication Image 1" style="max-width: 70%;  display: block;">
                <p style="margin-left: 14%"> <a href="https://bayesrays.github.io" target="_blank" rel="noopener noreferrer">Page</a> / <a href="https://arxiv.org/abs/2309.03185" target="_blank" rel="noopener noreferrer">Arxiv</a> / <a href="https://github.com/BayesRays/BayesRays/tree/main" target="_blank" rel="noopener noreferrer">Code</a></p>
            </div>
            <div style="flex: 1; padding: 20px;">
                <p> <b>Bayes’ Rays: Uncertainty Quantification for Neural Radiance Fields</b> </p>
                <p> <b>Lily Goli</b>, Cody Reading, Silvia Sellán, Alec Jacobson, Andrea Tagliasacchi </p>
                <p><i>CVPR 2024 (<b>Highlight</b>)</i></p>
            </div>
        </div>
        <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 20px;">
            <div style="flex: 1; padding: 20px;">
                <img src="/images/BANF.gif" alt="Publication Image 1" style="max-width: 70%;  display: block;">
                <p style="margin-left: 14%"> <a href="https://theialab.github.io/banf/" target="_blank" rel="noopener noreferrer">Page</a> / <a href="" target="_blank" rel="noopener noreferrer">Arxiv</a> / <a href="" target="_blank" rel="noopener noreferrer">Code</a></p>
            </div>
            <div style="flex: 1; padding: 20px;">
                <p> <b>BANF: Band-limited Neural Fields for Levels of Detail Reconstruction</b> </p>
                <p> Ahan Shabanov, Shrisudhan Govindarajan, Cody Reading, <b>Lily Goli</b>, Daniel Rebain, Kwang Moo Yi, Andrea Tagliasacchi </p>
                <p><i>CVPR 2024</i></p>
            </div>
        </div>
        <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 20px;">
            <div style="flex: 1; padding: 20px;">
                <img src="/images/n2n.gif" alt="Publication Image 1" style="max-width: 70%;  display: block;">
                <p style="margin-left: 2%"> <a href="https://nerf2nerf.github.io" target="_blank" rel="noopener noreferrer">Page</a> / <a href="https://arxiv.org/abs/2211.01600" target="_blank" rel="noopener noreferrer">Arxiv</a> / <a href="https://github.com/nerf2nerf/nerf2nerf" target="_blank" rel="noopener noreferrer">Code</a> / <a href="https://t.co/VNO1VjgWOO" target="_blank" rel="noopener noreferrer">CV News</a> <br> <a href="/files/nerf2nerf_slides.pdf" target="_blank" rel="noopener noreferrer">Talk at Google Geo (slides)</a></p>
            </div>
            <div style="flex: 1; padding: 20px;">
                <p> <b>nerf2nerf: Pairwise Registration of Neural Radiance Fields</b> </p>
                <p> <b>Lily Goli</b>, Daniel Rebain, Sara Sabour, Animesh Garg, Andrea Tagliasacchi </p>
                <p><i>ICRA 2023, CVPR workshop (<a href="https://sites.google.com/view/xrnerf/">XRNeRF</a>) 2023, Computer Vision News cover (March 2023)</i></p>
            </div>
        </div>
        <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 20px;">
            <div style="flex: 1; padding: 20px;">
                <img src="/images/long.png" alt="Publication Image 1" style="max-width: 70%;  display: block;">
                <p style="margin-left: 21%"> <a href="https://arxiv.org/abs/2103.07240" target="_blank" rel="noopener noreferrer">Arxiv</a> / <a href="https://github.com/lilygoli/longitudinalCOVID" target="_blank" rel="noopener noreferrer">Code</a></p>
            </div>
            <div style="flex: 1; padding: 20px;">
                <p> <b>Longitudinal Quantitative Assessment of COVID-19 Infection Pro-
gression from Chest CTs</b> </p>
                <p> <b>Lily Goli*</b>, Seong Tae Kim*, Magdalini Paschali, Ashkan Khakzar, Matthias Keicher, Tobias Czempiel, Egon Burian, Rickmer Braren, Nassir Navab, Thomas Wendler </p>
                <p><i>MICCAI 2021</i></p>
            </div>
        </div>
        <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 20px;">
            <div style="flex: 1; padding: 20px;">
                <img src="/images/adv1.png" alt="Publication Image 1" style="max-width: 70%; display: block;">
                <p style="margin-left: 30%"> <a href="https://arxiv.org/abs/2103.07640" target="_blank" rel="noopener noreferrer">Arxiv</a></p>
            </div>
            <div style="flex: 1; padding: 20px;">
                <p> <b>Generating Unrestricted Misclassified Examples via Three Parameters</b> </p>
                <p> Hanieh Naderi, <b>Lily Goli</b>, Shohreh Kasaei</p>
                <p><i> Multimedia Tools and Applications 2021</i></p>
            </div>
        </div> 
        <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 20px;">
            <div style="flex: 1; padding: 20px;">
                <img src="/images/adv2.png" alt="Publication Image 1" style="max-width: 70%;  display: block;">
                <p style="margin-left: 15%"> <a href="https://ieeexplore.ieee.org/document/9116889" target="_blank" rel="noopener noreferrer">Paper (IEEE Xplore)</a></p>
            </div>
            <div style="flex: 1; padding: 20px;">
                <p> <b>Scale Equivariant CNNs with Scale Steerable Filters</b> </p>
                <p> Hanieh Naderi, <b>Lily Goli</b>, Shohreh Kasaei</p>
                <p><i> Machine Vision and Image Processing (MVIP) 2020</i></p>
            </div>
        </div> 
    </div>
